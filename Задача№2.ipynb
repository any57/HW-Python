{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Задача№2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KxuGAjpGqyU",
        "outputId": "81a80837-583c-4491-dfa5-b4845e679555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "pip install pymorphy2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 1.8MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/9b/358faaff410f65a4ad159275e897b5956dcb20576c5b8e764b971c1634d7/pymorphy2_dicts_ru-2.4.404381.4453942-py2.py3-none-any.whl (8.0MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0MB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Installing collected packages: dawg-python, pymorphy2-dicts-ru, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.404381.4453942\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTDdsn7OtHGI",
        "outputId": "b765a5c5-6ba8-4943-8ae0-4d8a60e7666d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM-UcmxAGuI2"
      },
      "source": [
        "import pymorphy2\n",
        "from typing import Iterable,Union, List "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsXTD4ocZZFI",
        "outputId": "bc53c993-2f82-48ce-f25e-1ff40e0be2d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize,sent_tokenize\n",
        "nltk.download('averaged_perceptron_tagger_ru')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_ru is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWyAN2y5ADL5"
      },
      "source": [
        "class RussianSentence():\n",
        "  \"\"\"\"Класс RussianSentence используется для анализа русскоязычного предложения \n",
        "\n",
        "    Основное применение - определение характеристик предложения и слов в нем\n",
        "\n",
        "    Note:\n",
        "        Для корректной работы необходимо импортирование pymorphy2 \n",
        "    \n",
        "    Attributes\n",
        "    ----------\n",
        "    morph : pymorphy2.MorphAnalyzer()\n",
        "        экземпляр класса pymorphy2.MorphAnalyzer()\n",
        "    sentence : str\n",
        "        предложение для анализа\n",
        "    cnt : int\n",
        "        количество слов в предложении\n",
        "    cnt_lemm : list\n",
        "        список лемм предложения\n",
        "    list_pos_word : list\n",
        "        список слов предложения соответствующей части речи\n",
        "\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    get_words()\n",
        "        возвращает список слов\n",
        "    get_lemmas()\n",
        "        возвращает список лемм\n",
        "    get_pos(pos = )\n",
        "        принимает на вход название части речи, возвращает все\n",
        "        слова этой части речи из предложения в виде списка, в качестве аргумента pos \n",
        "        можно передать одну из частей речи\n",
        "        из набора для библиотеки nltk (http://code.google.com/p/universal-pos-tags/).\n",
        "   check_affirm()\n",
        "        возвращает 'Утвердительное'/'Вопросительное'/'Восклицательное' в зависимости от знака препинания на конце \n",
        "        (всё что не вопросительное и не восклицательное считается утвердительным) \n",
        "           \n",
        "    \"\"\"\n",
        "\n",
        "  morph = pymorphy2.MorphAnalyzer()\n",
        "  \n",
        "  def __init__(self, sentence):\n",
        "    self.sentence: str = sentence\n",
        "\n",
        "  def get_words(self) -> List[str]:\n",
        "    \"\"\"Метод для получения списка слов\"\"\"\n",
        "    self.cnt: List[str] = self.sentence.split(sep=\" \")\n",
        "\n",
        "    return self.cnt\n",
        "\n",
        "  def get_lemmas(self) -> List[str]: \n",
        "    \"\"\"Метод для получения списка лемм\"\"\"\n",
        "    \n",
        "    self.cnt_lemm: List[str] = [x for x in self.sentence.lower().split(sep = \" \") if x == self.morph.parse(x)[0].normal_form]\n",
        "    return self.cnt_lemm\n",
        "\n",
        "  def get_pos(self,pos: str) -> List[str]:\n",
        "    \"\"\"Метод для получения списка слов, определенной части речи\"\"\"\n",
        "\n",
        "    self.list_pos_word: List[str] = [x for x in self.sentence.lower().split(sep = \" \") if pos in nltk.pos_tag(x,tagset='universal',lang='rus')[0]]\n",
        "    return self.list_pos_word\n",
        "  \n",
        "  def check_affirm(self) -> str:\n",
        "    \"\"\"Метод для определения типа предложения по интонации (Повествовательное/Вопросительное/Восклицательное)\"\"\"\n",
        "    \n",
        "    if self.sentence.replace(\" \",\"\")[-1] == \"!\":\n",
        "      return \"Восклицательное\"\n",
        "    elif self.sentence.replace(\" \",\"\")[-1] == \"?\":\n",
        "      return \"Вопросительное\"\n",
        "    else:\n",
        "      return \"Повествовательное\"\n",
        "\n",
        "  def __del__(self):\n",
        "     \"\"\"деструктор, печатающий сообщение о том, что объект удален\"\"\"\n",
        "\n",
        "     return \"объект класса удален\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE3rmnQWrkau"
      },
      "source": [
        "class EnglishSentence():\n",
        "  \"\"\"\"Класс RussianSentence используется для анализа русскоязычного предложения \n",
        "\n",
        "    Основное применение - определение характеристик предложения и слов в нем\n",
        "\n",
        "    Note:\n",
        "        Для корректной работы необходимо импортирование nltk \n",
        "    \n",
        "    Attributes\n",
        "    ----------\n",
        "    sentence : str\n",
        "        предложение для анализа\n",
        "    cnt : int\n",
        "        количество слов в предложении\n",
        "    cnt_lemm : list\n",
        "        список лемм предложения\n",
        "    list_pos_word : list\n",
        "        список слов предложения соответствующей части речи\n",
        "\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    get_words()\n",
        "        возвращает список слов\n",
        "    get_lemmas()\n",
        "        возвращает список лемм\n",
        "    get_pos(pos = )\n",
        "        принимает на вход название части речи, возвращает все\n",
        "        слова этой части речи из предложения в виде списка, в качестве аргумента pos \n",
        "        можно передать одну из частей речи\n",
        "        из набора для библиотеки nltk (http://code.google.com/p/universal-pos-tags/).\n",
        "   check_affirm()\n",
        "        возвращает 'Утвердительное'/'Вопросительное'/'Восклицательное' в зависимости от знака препинания на конце \n",
        "        (всё что не вопросительное и не восклицательное считается утвердительным) \n",
        "           \n",
        "    \"\"\"\n",
        "\n",
        "  \n",
        "  def __init__(self, sentence: str):\n",
        "    self.sentence = sentence\n",
        "    self.words = nltk.word_tokenize(sentence.lower())\n",
        "\n",
        "  def get_words(self) -> List[str]:\n",
        "    \"\"\"Метод для получения списка слов\"\"\"\n",
        "\n",
        "    return self.words\n",
        "\n",
        "  def get_lemmas(self) -> List[str]:\n",
        "    \"\"\"Метод для получения списка лемм\"\"\"\n",
        "\n",
        "    self.cnt_lemm = [x for x in self.words if x == WordNetLemmatizer().lemmatize(x)]\n",
        "    return self.cnt_lemm\n",
        "\n",
        "  def get_pos(self,pos: str):\n",
        "    \"\"\"Метод для получения списка слов, определенной части речи\"\"\"\n",
        "\n",
        "    self.list_pos_word: List[str] = [x for x in self.words if pos in nltk.pos_tag(x,tagset='universal')[0]]\n",
        "    return self.list_pos_word\n",
        "  \n",
        "  def check_affirm(self):\n",
        "    \"\"\"Метод для определения типа предложения по интонации (Повествовательное/Вопросительное/Восклицательное)\"\"\"\n",
        "\n",
        "    if self.sentence.replace(\" \",\"\")[-1] == \"!\":\n",
        "      return \"Восклицательное\"\n",
        "    elif self.sentence.replace(\" \",\"\")[-1] == \"?\":\n",
        "      return \"Вопросительное\"\n",
        "    else:\n",
        "      return \"Повествовательное\"\n",
        "\n",
        "  def __del__(self):\n",
        "    return \"объект класса удален\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjyepSD5Ziyv"
      },
      "source": [
        "example_polymorphism_rus = RussianSentence(\"London is the capital of Great Britain\")\n",
        "example_polymorphism_eng = EnglishSentence(\"London is the capital of Great Britain\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWE-ufTbbtm8"
      },
      "source": [
        "В следующих ячейках одинаковые методы двух разных классов выводят разный результат при одном и том же аргументе"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_NPYqCrbODz",
        "outputId": "99f57229-22bb-46ee-f2a4-8d11fd09bbf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "example_polymorphism_rus.get_pos(\"NOUN\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWqDRj5BbSdZ",
        "outputId": "f8a1c0e5-bfac-4489-910d-fd2900c7e91d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "example_polymorphism_eng.get_pos('NOUN')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['london', 'is', 'the', 'of', 'great', 'britain']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX1pAT1ffQJW",
        "outputId": "ffd394d7-938b-4a98-af17-1067a4666720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#example_polymorphism_rus.get_words()\n",
        "example_polymorphism_rus.get_lemmas()\n",
        "#example_polymorphism_rus.check_affirm()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['london', 'is', 'the', 'capital', 'of', 'great', 'britain']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    }
  ]
}